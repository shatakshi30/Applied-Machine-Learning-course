# Module 01: Application of ML in Computer Vision

### Assignment Summary
This assignment introduced foundational machine learning concepts using two classic datasets: **Iris** and **Wine**. The goal was to explore feature distributions, perform visualizations, and implement basic classification and clustering techniques.

### Tasks Covered
- Defined key ML terms: training/testing/validation datasets, ground truth, preprocessing, decision surface, model validation, overfitting, and more.
- Loaded and explored the **Iris** and **Wine** datasets using scikit-learn.
- Computed feature statistics (means, categories, data types) for both datasets.
- Visualized the Iris dataset with pairplots to identify feature combinations offering good class separation.
- Proposed an unsupervised clustering strategy for the Iris dataset, including manual grouping and feature range identification.
- Trained and evaluated two classifiers (Naive Bayes and Decision Tree) on the Iris dataset.
- Compared performance across varying training sizes and plotted the accuracy trend to observe the plateau effect.

### Highlights
- Identified **petal length** and **petal width** as the most discriminative features in the Iris dataset.
- Observed Naive Bayes performed better with small training sizes, while Decision Tree excelled as training data increased.
- Demonstrated that model performance plateaus beyond a certain training threshold.

### File
- `Shewale-Assign1.ipynb`: Complete notebook with explanations, code, plots, and answers.
